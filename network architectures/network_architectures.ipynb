{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the data_processing file to get the training and validation sets\n",
    "\n",
    "%run ../data_processing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile parameters (can be updated for different variations and test)\n",
    "X_TRAIN = x_train\n",
    "Y_TRAIN = y_train\n",
    "\n",
    "X_VALID = x_valid\n",
    "Y_VALID = y_valid\n",
    "\n",
    "VALIDATION = (x_valid, y_valid)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.03\n",
    "LOSS_FUNCTION = 'categorical_crossentropy'\n",
    "VERBOSE = 0\n",
    "\n",
    "# dataframe to hold the loss and accuracy for each loss function\n",
    "df_result = pd.DataFrame(columns=['learning_rate', 'training_loss',\n",
    "                                  'training_accuracy', 'validation_loss',\n",
    "                                  'validation_accuracy'])\n",
    "\n",
    "# clears the dataset to avoid redundancy\n",
    "df_result = df_result.iloc[0:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
